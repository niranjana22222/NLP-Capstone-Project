{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86787d86-3187-4604-8aee-f1b69a5232e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding queries and captions:\n",
    "\n",
    "#Process captions/queries by lowercasing the text, removing punctuation, and tokenizing words based on white space. Refer to the “bag of words” exercise notebook for efficient code for striping punctuation out of a string\n",
    "\n",
    "#Take our vocabulary to be all words across all captions in the COCO dataset. Treating each caption as its own “document” compute the inverse document frequency for each word in the vocabulary. Efficiency is important here!\n",
    "\n",
    "#Make a function that can embed any caption / query text (using GloVe-200 embeddings weighted by IDFs of words across captions)\n",
    "\n",
    "#An individual word not in the GloVe or IDF vocabulary should yield an embedding vector of just zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d201529-20f4-49a2-b0eb-c4f41c335777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cogworks_data.language import get_data_path\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# load COCO metadata\n",
    "filename = get_data_path(\"captions_train2014.json\")\n",
    "with Path(filename).open() as f:\n",
    "    coco_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ce29a-3a5f-4b4d-8afb-5eb1ea73aa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1522ef7-0031-4280-af90-6dddac627861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'glove.6B.200d.txt.w2v' from 'https://github.com/rsokl/cog_data/releases/download/language-files/glove.6B.200d.txt.w2v' to '/Users/andrew/Library/Caches/cog_data'.\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "punc_regex = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "from gensim.models import KeyedVectors\n",
    "filename = \"glove.6B.200d.txt.w2v\"\n",
    "\n",
    "# this takes a while to load -- keep this in mind when designing your capstone project\n",
    "glove = KeyedVectors.load_word2vec_format(get_data_path(filename), binary=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2f0c741-bbbd-47f3-a6f1-c855eb664375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58389f2-11ae-4bd2-9c35-16b908e5d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_captions(captions):\n",
    "    words = []\n",
    "    for caption in captions:\n",
    "        cleaned_caption = punc_regex.sub('', caption).lower()\n",
    "        words = cleaned_caption.split()\n",
    "        words.extend(words)\n",
    "\n",
    "    word_counts = Counter(words)\n",
    "    num_docs = len(captions)\n",
    "    weights = {word: np.log10(num_docs / count) for word, count in word_counts.items()}\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa50f8-6201-4fb0-983d-2fc446e77689",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions = [caption_info[\"caption\"] for caption_info in coco_data[\"annotations\"]]\n",
    "idf_weights = preprocess_captions(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c040412b-b72e-48c2-8635-5092d0fe80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_caption(caption, dim=200):\n",
    "    \n",
    "    cleanCap = punc_regex.sub('', caption).lower()\n",
    "    tokens = cleanCap.split()\n",
    "\n",
    "    real_embeddings = []\n",
    "    for word in tokens:\n",
    "        if word in glove:\n",
    "            idf = idf_weights.get(word)\n",
    "            real_embeddings.append(idf * glove[word])  # Directly calculate weighted embedding\n",
    "        else:\n",
    "            real_embeddings.append(np.zeros(dim))  # Zero vector for missing words\n",
    "    if not real_embeddings:  #No words\n",
    "        return np.zeros(dim)\n",
    "    \n",
    "    # Sum\n",
    "    caption_embedding = np.sum(real_embeddings, axis=0) \n",
    "    normalized_embedding = caption_embedding / np.linalg.norm(caption_embedding)  # Normalize\n",
    "    return normalized_embedding\n",
    "\n",
    "all_embeddings = [embed_caption(caption) for caption in all_captions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64525d31-71cd-4438-a1bf-ca07b11b5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a function that can embed any caption / query text (using GloVe-200 embeddings weighted by IDFs of words across captions)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc255f4f-49a9-4177-8822-69da57b3760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc68b7-4eb5-48e1-a783-bdb85e267019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
